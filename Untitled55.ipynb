{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e775db-5e70-46a2-bb0b-f7ceee691e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear Regression: Used for predicting continuous numerical values. \n",
    "                   Provides a linear relationship between variables.\n",
    "\n",
    "Logistic Regression: Used for binary or categorical outcomes, predicting probabilities between 0 and 1. \n",
    "                     Ideal for binary classification scenarios, such as yes/no or pass/fail predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f9ece7-a0b1-4132-8e4c-8f339abea673",
   "metadata": {},
   "outputs": [],
   "source": [
    "In logistic regression, the cost function used is the logistic loss (log loss) function. It measures the error between\n",
    "predicted probabilities and actual binary outcomes.\n",
    "Optimization is typically done using gradient descent,\n",
    "adjusting model parameters iteratively to minimize the cost and improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a416d-5fa9-48d5-ae5c-14103182cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization in logistic regression prevents overfitting by adding a penalty to the model's complexity.\n",
    "It discourages large coefficient values, leading to simpler and more generalizable models.\n",
    "L1 (Lasso) regularization can even eliminate irrelevant features, further reducing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65325f2-bb22-4b31-bb4c-88346d756012",
   "metadata": {},
   "outputs": [],
   "source": [
    "The ROC curve is a visual tool to evaluate the performance of binary classification models like logistic regression. \n",
    "It shows how well the model distinguishes between true positives and false positives at various classification thresholds. The Area Under the Curve (AUC) quantifies this performance,\n",
    "with a higher AUC indicating better model discrimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dae817-32b8-4e05-89c9-a1586e23034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Common techniques for feature selection in logistic regression include statistical tests, regularization (L1), tree-based feature importance, and domain knowledge.\n",
    "These techniques help improve the model's performance by reducing overfitting, enhancing interpretability, increasing efficiency, and enhancing robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960b1f5-546a-4902-a468-b0260935aafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
